{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNns19F8M8gpCdNHOxRwh0w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJhawar1010/NLP/blob/main/Satyam_554_Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-pFd3z_7k6e",
        "outputId": "54023457-f8ce-447e-b787-9fc2f75d92a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "PsZdDNu26Lmj"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_antonyms(word):\n",
        "    antonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            for antonym in lemma.antonyms():\n",
        "                antonyms.add(antonym.name())\n",
        "    return antonyms\n",
        "\n",
        "word = \"good\"\n",
        "antonyms = get_antonyms(word)\n",
        "print(f\"Antonyms of '{word}': {antonyms}\")"
      ],
      "metadata": {
        "id": "_Ozo_YiHGzrJ",
        "outputId": "70c11940-2c66-422a-d591-89bc4cbd7c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms of 'good': {'ill', 'bad', 'badness', 'evilness', 'evil'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"smart\"\n",
        "antonyms = get_antonyms(word)\n",
        "print(f\"Antonyms of '{word}': {antonyms}\")"
      ],
      "metadata": {
        "id": "IhRlw3tDG2fy",
        "outputId": "ac89a134-7a0b-4c0e-966a-bc3cb1b8ab4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms of 'smart': {'stupid'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"intelligent\"\n",
        "antonyms = get_antonyms(word)\n",
        "print(f\"Antonyms of '{word}': {antonyms}\")"
      ],
      "metadata": {
        "id": "HBF5iiNHG58F",
        "outputId": "50dd006f-3fda-41c1-d24e-9411b740a717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms of 'intelligent': {'unintelligent'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"love\"\n",
        "antonyms = get_antonyms(word)\n",
        "print(f\"Antonyms of '{word}': {antonyms}\")"
      ],
      "metadata": {
        "id": "PaNLVgDMG7pG",
        "outputId": "a0733cb3-7a8f-4913-9fd7-83310810721d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms of 'love': {'hate'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"death\"\n",
        "antonyms = get_antonyms(word)\n",
        "print(f\"Antonyms of '{word}': {antonyms}\")"
      ],
      "metadata": {
        "id": "Z8Tg2KWHG-Qa",
        "outputId": "be3ee471-419a-4905-f67d-531c2bba7fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antonyms of 'death': {'birth'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from snowballstemmer import stemmer\n",
        "\n",
        "def stem_non_english_word(word, language):\n",
        "    stem = stemmer(language)\n",
        "    return stem.stemWord(word)\n",
        "\n",
        "word = \"alumnos\"\n",
        "language = \"spanish\"\n",
        "stemmed_word = stem_non_english_word(word, language)\n",
        "print(f\"Stemmed word of '{word}' in {language}: {stemmed_word}\")"
      ],
      "metadata": {
        "id": "NTKpGdsrHB29",
        "outputId": "a966725c-24ab-4153-8a22-42c5b7c51d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed word of 'alumnos' in spanish: alumn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_word(word):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return lemmatizer.lemmatize(word)\n",
        "\n",
        "word = \"running\"\n",
        "lemmatized_word = lemmatize_word(word)\n",
        "print(f\"Lemmatized word of '{word}': {lemmatized_word}\")"
      ],
      "metadata": {
        "id": "P6c4BaL6HMIk",
        "outputId": "d915fa7b-3581-4ba5-de9a-700eccb8893e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized word of 'running': running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "def stem_and_lemmatize_word(word):\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    lemmatized_word = lemmatizer.lemmatize(word)\n",
        "    return stemmed_word, lemmatized_word\n",
        "\n",
        "word = \"running\"\n",
        "stemmed_word, lemmatized_word = stem_and_lemmatize_word(word)\n",
        "print(f\"Original Word: {word}\")\n",
        "print(f\"Stemmed Word: {stemmed_word}\")\n",
        "print(f\"Lemmatized Word: {lemmatized_word}\")"
      ],
      "metadata": {
        "id": "juEW8vrGHP3K",
        "outputId": "0a7e836d-5885-4cef-bbdf-9b5d87f4b6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: running\n",
            "Stemmed Word: run\n",
            "Lemmatized Word: running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "XkIu824zH3FJ",
        "outputId": "01ae0364-f698-448e-ff8d-e0f6adb0400d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "4QAM4O_cH_Tb",
        "outputId": "879f1641-a873-41e4-d339-d519d7d00f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Satyam likes to play cricket all the time.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform PoS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(\"PoS tagging:\")\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "EpKrCFG4HVLu",
        "outputId": "3cf6eec2-fb3a-4346-979a-70f7aa849183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS tagging:\n",
            "[('Satyam', 'NNP'), ('likes', 'VBZ'), ('to', 'TO'), ('play', 'VB'), ('cricket', 'NN'), ('all', 'PDT'), ('the', 'DT'), ('time', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "GOtkZAQ8II04",
        "outputId": "4a6b3d86-0495-4aa0-db7c-6b9dd2005806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform NER\n",
        "ner_tags = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
        "\n",
        "print(\"Named Entity Recognition:\")\n",
        "print(ner_tags)"
      ],
      "metadata": {
        "id": "ZFHJ35TXHuFy",
        "outputId": "1629f060-f411-403d-95b4-22fa52a79134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition:\n",
            "(S\n",
            "  (GPE Satyam/NNP)\n",
            "  likes/VBZ\n",
            "  to/TO\n",
            "  play/VB\n",
            "  cricket/NN\n",
            "  all/PDT\n",
            "  the/DT\n",
            "  time/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanfordnlp\n"
      ],
      "metadata": {
        "id": "5TSk8hqFIGLb",
        "outputId": "26419b0c-20f5-4f38-cf46-a34065fb2e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'stanfordnlp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-5d3e57dcfa26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstanfordnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stanfordnlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdaJO9AaIUhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}