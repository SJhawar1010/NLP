{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJhawar1010/NLP/blob/main/Satyam_554_Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee6af155",
      "metadata": {
        "id": "ee6af155"
      },
      "source": [
        "### Antonyms from WordNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324b2044",
      "metadata": {
        "id": "324b2044",
        "outputId": "796dc5c8-6983-466d-e73a-569320f1720a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Antonym of  good  is  evil\n",
            "Antonym of  good  is  evilness\n",
            "Antonym of  good  is  bad\n",
            "Antonym of  good  is  badness\n",
            "Antonym of  good  is  bad\n",
            "Antonym of  good  is  evil\n",
            "Antonym of  good  is  ill\n",
            "Antonym of  bad  is  good\n",
            "Antonym of  bad  is  goodness\n",
            "Antonym of  bad  is  good\n",
            "Antonym of  bad  is  unregretful\n",
            "Antonym of  big  is  small\n",
            "Antonym of  big  is  little\n",
            "Antonym of  big  is  small\n",
            "Antonym of  small  is  large\n",
            "Antonym of  small  is  big\n",
            "Antonym of  small  is  big\n",
            "Antonym of  worse  is  better\n",
            "Antonym of  worse  is  better\n",
            "Antonym of  worse  is  good\n",
            "Antonym of  worse  is  unregretful\n"
          ]
        }
      ],
      "source": [
        "words=['good','bad','big','small','worse']\n",
        "from nltk.corpus import wordnet\n",
        "for i in words:\n",
        "    for syn in wordnet.synsets(i):\n",
        "        for l in syn.lemmas():\n",
        "            if l.antonyms():\n",
        "                print(\"Antonym of \",i,\" is \",l.antonyms()[0].name())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1542f713",
      "metadata": {
        "id": "1542f713"
      },
      "source": [
        "### Stemming non-English words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef26c6d",
      "metadata": {
        "id": "1ef26c6d",
        "outputId": "d52e04f8-fd6c-4f2b-e2ef-96ebe5233990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Schreiben  post stemming is  schreib\n",
            "geschrieben  post stemming is  geschrieb\n",
            "Hunde  post stemming is  hund\n",
            "Pferde  post stemming is  pferd\n",
            "Männer  post stemming is  mann\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.snowball import GermanStemmer\n",
        "gst = GermanStemmer()\n",
        "german=['Schreiben','geschrieben','Hunde','Pferde','Männer']\n",
        "for i in german:\n",
        "    print(i,\" post stemming is \",gst.stem(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669125cb",
      "metadata": {
        "id": "669125cb"
      },
      "source": [
        "### Differentiate between stemming and lemmatizing words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1c67b4",
      "metadata": {
        "id": "aa1c67b4",
        "outputId": "1633cc77-de8c-4b3c-9dce-e1971c2fdf26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apples  after WordnetLemmatizer- apple\n",
            "apples  after PortStemmer- appl\n",
            "apples  after LancasterStemmer- appl\n",
            "apples  after Snowball Stemmer- appl\n",
            "ladies  after WordnetLemmatizer- lady\n",
            "ladies  after PortStemmer- ladi\n",
            "ladies  after LancasterStemmer- lady\n",
            "ladies  after Snowball Stemmer- ladi\n",
            "words  after WordnetLemmatizer- word\n",
            "words  after PortStemmer- word\n",
            "words  after LancasterStemmer- word\n",
            "words  after Snowball Stemmer- word\n",
            "kicks  after WordnetLemmatizer- kick\n",
            "kicks  after PortStemmer- kick\n",
            "kicks  after LancasterStemmer- kick\n",
            "kicks  after Snowball Stemmer- kick\n",
            "games  after WordnetLemmatizer- game\n",
            "games  after PortStemmer- game\n",
            "games  after LancasterStemmer- gam\n",
            "games  after Snowball Stemmer- game\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "words=['apples','ladies','words','kicks','games']\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer('english')\n",
        "for i in words:\n",
        "    print(i,\" after WordnetLemmatizer-\",lemmatizer.lemmatize(i))\n",
        "    print(i,\" after PortStemmer-\",porter.stem(i))\n",
        "    print(i,\" after LancasterStemmer-\",lancaster.stem(i))\n",
        "    print(i,\" after Snowball Stemmer-\",snowball.stem(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "586f9b81",
      "metadata": {
        "id": "586f9b81"
      },
      "source": [
        "### PoS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d541bd69",
      "metadata": {
        "id": "d541bd69",
        "outputId": "cc909380-041b-49da-f411-474404b4f642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('My', 'PRP$')]\n",
            "[('name', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('Himanshu', 'NN')]\n",
            "[('Gulechha', 'NN')]\n",
            "[('.', '.')]\n",
            "[('I', 'PRP')]\n",
            "[('am', 'VBP')]\n",
            "[('24', 'CD')]\n",
            "[('years', 'NNS')]\n",
            "[('old', 'JJ')]\n",
            "[('.', '.')]\n",
            "[('I', 'PRP')]\n",
            "[('am', 'VBP')]\n",
            "[('the', 'DT')]\n",
            "[('best', 'JJS')]\n",
            "[('!', '.')]\n"
          ]
        }
      ],
      "source": [
        "text='My name is Himanshu Gulechha. I am 24 years old. I am the best!'\n",
        "from nltk import pos_tag, word_tokenize\n",
        "for i in word_tokenize(text):\n",
        "    print(pos_tag(word_tokenize(i)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04cddd2b",
      "metadata": {
        "id": "04cddd2b"
      },
      "source": [
        "### Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d277380",
      "metadata": {
        "id": "5d277380",
        "outputId": "e87c8df2-0339-4585-f6d8-73a9080ae3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERSON Himanshu Gulechha\n"
          ]
        }
      ],
      "source": [
        "from nltk import ne_chunk\n",
        "entity=ne_chunk(pos_tag(word_tokenize(text)))\n",
        "for chunk in entity:\n",
        "    if hasattr(chunk, 'label'):\n",
        "        print(chunk.label(), ' '.join(c[0] for c in chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa15c30",
      "metadata": {
        "id": "7fa15c30"
      },
      "source": [
        "### Dependency Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd48b15",
      "metadata": {
        "id": "1cd48b15"
      },
      "source": [
        "![Screenshot%202024-03-19%20at%208.49.37%E2%80%AFPM.png](attachment:Screenshot%202024-03-19%20at%208.49.37%E2%80%AFPM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78615a0b",
      "metadata": {
        "id": "78615a0b"
      },
      "source": [
        "### Constituency Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a045fd2",
      "metadata": {
        "id": "3a045fd2"
      },
      "source": [
        "![Screenshot%202024-03-19%20at%208.44.52%E2%80%AFPM.png](attachment:Screenshot%202024-03-19%20at%208.44.52%E2%80%AFPM.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}